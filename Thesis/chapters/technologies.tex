\setauthor{Luna Klatzer}

This chapter will discuss the technologies selected and utilized in the Kipper project, detailing their application and comparing them to alternative tools and technologies. It will explore the reasoning behind these choices and evaluate their effectiveness in achieving the project's goals.

\section{Background}
\setauthor{Luna Klatzer}
\label{sec:technology-background}

Before introducing the technologies and tools used in the Kipper project, it is important to note that the project existed on a smaller scale prior to the initiation of this diploma thesis. As such, the following sections will discuss technologies—TypeScript and \Gls{antlr4}—that were chosen before the start of this thesis project. 

Consequently, when the project was re-envisioned and expanded into its current form as part of this diploma thesis, the development technologies had already been determined and were simply continued to build upon the existing foundation (see \nameref{chapter:appendix_a} for further details on the project's foundation prior to this thesis).

Nevertheless, to highlight the various alternatives and the reasons behind the original decisions for the parser, lexer, and core compiler, the following sections will still examine each option, assess their viability within the context of this project, and elaborate on the choices made when the initial project was conceived.

\section{Development Language}
\setauthor{Luna Klatzer}
\label{sec:development-language}

The choice of development language, or compiler programming language, is a crucial initial decision when starting a project of this nature. This decision significantly impacts factors such as distribution, accessibility, and cross-platform integration. The selected language sets the foundational conditions for the entire project and influences the ability to effectively utilize the language being created.

Many compilers are initially developed in a different language, often one closely related to the language being designed. Once the language takes on proper shape, the compilers are then often migrated into the newly created language, effectively becoming one of the first test programs to utilize the language directly. This approach allows the compiler to validate its own functionality—serving as a self-serving cycle where each iteration of updates also benefits the compiler itself.

This is not the case here, however. As the Kipper compiler remains too complex for its own language, it is currently written in another language. Nonetheless, the compiler could be migrated to the Kipper language in the future if the required changes are implemented.

\subsection{Selection criteria and weighing the options}
\label{sec:development-language-selection-criteria}

To accurately represent the various benefits and downsides of each individual option, we are going to rank each language based on a set of criteria with individual weights which will amount to a certain total score as presented in table~\ref{tab:programming-language-criteria-weights}. Based on this score we can accurately represent the viability of each technology option presented.

\begin{table}[H]
	\centering
	\begin{tabular}{ |p{4cm}|p{5cm}|p{5cm}|  }
		\hline
		\multicolumn{3}{|c|}{Weights for the individual criteria} \\
		\hline
		Criterion&Weight between 0.0-1.0&Effective maximum possible score on a scale of 0-100\\
		\hline
		Speed&0.4&40\\
		Maintainability&1.0&100\\
		Platform Support&0.5&50\\
		Extensibility&0.4&40\\
		Similarity to Kipper&0.8&80\\
		\hline
	\end{tabular}
	\caption{Table showcasing the individual criteria for the programming language and their weights}
	\label{tab:programming-language-criteria-weights}
\end{table}

\subsection{Option - C++}
\label{sec:programming-language-option-c++}

C++ is widely recognized as one of the most prominent languages for low-level development and system programming, including compiler development. In addition to offering fast execution speeds, it provides flexible mechanisms like pointers for structuring essential constructs such as trees. The language utilizes~\acrshort{oop} to manage complex structures efficiently and supports templating, often also called generic type parameters, enabling versatile structures with unified behaviour and compatibility.

\subsubsection{Speed}

In terms of speed, C++ is mostly unrivalled, given the output to assembly code that can be directly run on the CPU without any overhead or interpreter. This would allow a compiler to be similarly fast and efficient, allowing even large programs to be compiled and translated quickly.

\subsubsection{Maintainability}

In compiler development, C++ is a common choice due to the wide-spread emphasis on minimizing compilation time and efficient processing of large programs. However, the complexity of memory management and the challenges associated with developing large structures can make C++ difficult to work with, potentially leading to unexpected development issues.

\subsubsection{Platform Support}

Furthermore, targeting multiple environments and systems is challenging, as C++ and by extension C commonly compile directly to machine and os-dependent assembly code, which means compiling the program for each operating system and architecture individually is necessary. Otherwise without virtualisation or subsystems the program can not be executed.

\subsubsection{Extensibility}

Due to the design of C++, the compiled code is largely locked down and any extensions to the compiler would have to be loaded using custom loaders or the user would have to fully re-compile the source code with the wanted changes.

\subsubsection{Similarity to Kipper}

While C++ aims to be more modern compared to its predecessor C, it still is largely a low-level language where programs needs to be structured with a lot of potential edge cases and faults in mind. Kipper on the other hand is a pure high-level \gls{transpilation}-based language with interpreted dynamic targets, so concepts such as memory management, integer sizes and segmentation faults are largely alien. This means if a compiler were to be written in C++, it would require a lot of additional code taking these C++ concepts into account that would have to be removed or heavily altered in a potential succeeding Kipper-based compiler.

\subsection{Option - Java}
\label{sec:programming-language-option-java}

Java is another commonly used~\acrshort{oop} language for building compilers and compiler components. As a matter of fact, \Gls{antlr4}, the lexer and parser generation technology, is developed solely in Java and for extended support simply provides output targets for its lexers and parsers used within other languages.

\subsubsection{Speed}

Speed is not a major concern when working with Java. The language and its VM are largely optimised and the~\acrshort{jit} compiler performs additional optimisations at runtime by analysing the code and the memory of the program. It may in some cases be slower, especially due to the large amount of boilerplate present in a lot of systems, but it can overall be considered fast.

\subsubsection{Maintainability}

Java can be considered a pure~\acrshort{oop} programming language, as all executable code is written in class methods, which can be called up and run from other parts of the program. Due to this all functionality adheres to some structure and is usually encapsulated in various classes and methods. While these features alone do not guarantee code that is easy to work with, they simplify that process and provide structures that can be easily changed or altered using inheritance or other functionality. However it often also leads to boilerplate-heavy code that is hard to read especially when programs become complex.

\subsubsection{Platform Support}

Java utilizes a VM in combination with a~\acrshort{jit} compiler for executing its intermediate code. This intermediate code is largely system-independent and can be run on any system that has a working Java runtime installed. As such, the responsibility of handling the individual characteristics of each operating system and architecture is left up the Java runtime, which makes compiling fairly simple and allows for a broad support of various systems.

\subsubsection{Extensibility}

Besides providing support for multiple platforms, the architecture of Java allows it to be an easy language to set up and extend, as its modularity means loading additional code simply means compiling it to the same standardised intermediate format. Using a class loader, this new runnable code can be then picked up at runtime and immediately executed. Additionally, the source code classes can be referenced and used within subsequent implementations that extend the original compiler functionality.

\subsubsection{Similarity to Kipper}

Java is fairly similar to Kipper in its~\acrshort{oop} design paradigm, but is still generally very different. Kipper runs as JavaScript or TypeScript in an interpreted environment, where code is ran line per line. While this is similar to the~\acrshort{jit} compiler utilised by Java, Kipper can run high-level code and execute on-demand changes without compiling its code or having to generate intermediate code. Given though that structurally the two languages are very similar, migrating from a compiler written in Java to one written in Kipper would be mostly straightforward.

\subsection{Option - TypeScript}
\label{sec:programming-language-option-typescript}

TypeScript is a super-set of JavaScript, which works on the same dynamically-typed and interpreted system and is during runtime de-facto the same language. As such, it is generally not preferred when it comes to implementing a compiler, since its dynamic structure and functionality do not serve a lot of use in a compiler with very specific functionality and limit performance. Still, it is often used for experiments and online compilers, which may not perform as well, but can still achieve good performance.

\subsubsection{Speed}

In terms of speed, TypeScript can be very fast, almost as fast as~\acrshort{wasm} in some cases. Although it still generally has the same limitations as any other web language. Given that the language needs interpretation and does not utilise JIT compilation or a compiled format, it often can not compete with languages such as Java, C++ or C\#. Still, with its heavily optimised interpreter regular algorithms and programs can be fast, but as complexity grows it is not as efficient as comparable languages.

\subsubsection{Maintainability}

In terms of maintainability TypeScript is generally regarded as maintainable, due to its simplified interpreter structure and detailed compiler errors, but also as problematic due to its common problems that are caused by its own compile-time only types and limitations in performing proper runtime checks or accounting runtime values into a given program. Great care must be put how specific operations are performed and how dynamic data is handled, as errors can easily occur due to oversight or negligence in appropriate type checks.

\subsubsection{Platform Support}

TypeScript, or its generated JavaScript counterpart, can run on any system that has a browser or a local browser-like counterpart like \Gls{nodejs}, \Gls{deno} or \Gls{bun} installed. However, every version of the JavaScript interpreprogramming-language-criteria-weightster comes with its own limitations and even in browsers running code can cause problems across various systems. This is more noticeable with locally installed systems such as \Gls{nodejs}, \Gls{deno} or \Gls{bun}, which implement their own libraries and design systems that need to be accounted for. Generally it can be said though that if the correct environment is set up, the code can run on any OS or architecture without issue. In the case of a standard browser, this often becomes even more simple, as browsers try to largely implement the same standards and concepts so that websites and their JavaScript code can run with identical results.

\subsubsection{Extensibility}

TypeScript is a very dynamic language with a lot of flexibility in terms of extending and modifying structures with ease. Even if a compiler were not able to support modifications, hooking into the object and modifying it if needed is relatively easy. Additionally by simply providing interfaces and specific arguments that need to be implemented a compiler could allow custom classes and data to be executed. Furthermore, referencing the original classes and objects is fairly simple and like Java can be used for subsequent implementations and custom versions of the compiler.

\subsubsection{Similarity to Kipper}

TypeScript serves as the primary inspiration for Kipper and shares many similarities with it, despite its limitations and challenges related to type safety. This similarity arises from Kipper's design goal of maintaining compatibility with the JavaScript ecosystem and extending it in a type-safe manner. Consequently, Kipper avoids incorporating functionality or design structures that could break compatibility with existing JavaScript tools and frameworks. With this in mind, theoretically any TypeScript code could be inserted into Kipper with only certain syntax changes and type safety changes necessary.

\subsection{Result}

Based on the analysis performed on each of the options listed in sections~\ref{sec:programming-language-option-c++},~\ref{sec:programming-language-option-java} and~\ref{sec:programming-language-option-typescript}, the following results were determined as presented in table~\ref{tab:programming-language-results}.

\begin{table}[H]
	\centering
	\begin{tabular}{ |p{2cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.2cm}|  }
		\hline
		\multicolumn{7}{|c|}{Result values for the criteria selected in~\ref{sec:development-language-selection-criteria}} \\
		\hline
		Language&Speed&Maintain- ability&Platform Support&Extensi- bility&Similarity to Kipper&Result\\
		\hline
		C++&40&50&20&10&30&150\\
		Java&35&80&40&30&55&240\\
		TypeScript&25&70&50&40&70&255\\
		\hline
	\end{tabular}
	\caption{Table showcasing the individual criteria and the scores each language scored}
	\label{tab:programming-language-results}
\end{table}

As presented in the table~\ref{tab:programming-language-results}, C++ is the least adequate with 150 points scored, Java is largely satisfactory in second place with its 240 points scored and TypeScript is the most suitable with 255 points in total. While TypeScript did not score as well as the other two in the "Speed" criterion, it was mostly first place or close behind Java in all other criteria. 

This result supports the pre-existing decision presented in section~\ref{sec:technology-background}.

\section{Parser \& Lexer Technology}
\setauthor{Luna Klatzer}

The choice of parser and lexer technology, alongside the development language, is a critical factor in the efficiency, extensibility, and maintainability of a programming language. Parsing is inherently complex and can contribute significantly to compilation time. While many language compilers implement custom parsers from scratch to optimise efficiency and minimise execution time, employing parser and lexer generation technology can offer notable advantages.

Using a parser and lexer generator provides greater flexibility, allowing modifications to the language grammar with minimal effort. Additionally, these tools often support multiple languages and compilation targets, enhancing adaptability if the language evolves or expands to additional platforms in the future.

\subsection{Selection criteria and weighing the options}
\label{sec:parser-and-lexer-technology-selection-criteria}

To accurately represent the various benefits and downsides of each individual option, we are going to rank each technology based on a set of criteria with individual weights which will amount to a certain total score as presented in table~\ref{tab:parser-and-lexer-technology-selection-criteria}. Based on this score we can accurately represent the viability of each parser \& lexer generator option presented.

\begin{table}[H]
	\centering
	\begin{tabular}{ |p{4cm}|p{5cm}|p{5cm}|  }
		\hline
		\multicolumn{3}{|c|}{Weights for the individual criteria} \\
		\hline
		Criterion&Weight between 0.0-1.0&Effective maximum possible score on a scale of 0-100\\
		\hline
		Speed&0.6&60\\
		Integration&1&100\\
		Maintainability&0.8&80\\
		\hline
	\end{tabular}
	\caption{Table showcasing the individual criteria for the parser \& lexer technology and their weights}
	\label{tab:parser-and-lexer-technology-selection-criteria}
\end{table}

\subsection{Option - Antlr4}
\label{sec:parser-technology-option-antlr4}

\Gls{antlr4} is one of the most widely used lexer and parser generators employing a top-down LL(*) parsing process, offering a comprehensive set of tools and multiple output targets, including a target for native TypeScript. It processes Antlr-specific grammar files and, based on the defined tokens and syntax rules, generates both a lexer and a parser, which are individually executable. Using either a listener or a visitor approach, the resulting parse tree can be traversed and transformed into an \acrshort{ast} for subsequent compilation~\cite{antlr}.

Although \Gls{antlr4} provides extensive tooling and allows for the extraction of detailed metadata from source code, its generated lexer and parser are generally not considered highly performant compared to the alternatives. Parsing can take a significant amount of time, particularly for large programs. While \Gls{antlr4} employs various optimisation techniques—such as improving performance over time as the parser "warms up" and refines its internal connections—the generic design and modularity introduce overhead that hinders performance optimisations commonly found in other parsing technologies.

Additionally, \Gls{antlr4} generates detailed objects and multiple context objects for each token and tree node, leading to high memory consumption. However, in most modern use cases, this is not a major concern.

\subsection{Option - Coco/R}
\label{sec:parser-technology-option-coco}

Coco/R is a compiler generator that, based on a grammar file, produces a scanner (lexer) and parser employing top-down LL(*) parsing capable of validating the syntactic integrity of a file while also performing semantic and type analysis. Unlike a pure lexer and parser generator, Coco/R integrates aspects of semantic analysis into its processing, thereby optimising performance by preemptively conducting checks that do not require complex context-based analysis~\cite{coco}~\cite{coco-manual}.

By instantiating the scanner and parser within a compiler class, Coco/R-generated classes can be used in a manner similar to \Gls{antlr4}. However, for generating an \acrshort{ast}, Coco/R grammars can be directly configured to construct a tree and build individual custom nodes, similar to the process of generating a parse tree. Using the generated \acrshort{ast}, subsequent processing and translation can be performed in a manner nearly identical to \Gls{antlr4}~\cite{coco-ast}.

Unlike \Gls{antlr4}, however, Coco/R does not provide an explicit target for TypeScript. Supporting TypeScript would require either implementing a custom target or translating the generated C\# or Java code into \acrshort{wasm}, which could then be executed within a TypeScript context. Both approaches would require significant development effort but could likely surpass \Gls{antlr4} in performance.

\subsection{Option - GNU Bison}
\label{sec:parser-technology-option-bison}

GNU Bison is a parser generator that employs a bottom-up LR parsing algorithm to validate the syntactic structure of an input token stream~\cite{bison}. Unlike \Gls{antlr4} or Coco/R, Bison primarily generates parsers for C and C++, with an experimental Java target also available. This focus on lower-level languages provides performance advantages, as Bison is highly efficient~\cite{bison-manual}.

Bison processes a grammar definition file and generates a parser that integrates with a lexer, typically implemented using Flex~\cite{flex}. While it offers strong performance, it lacks a native TypeScript target. Integrating Bison with a TypeScript-based project would require running the generated C/C++ code via \acrshort{wasm} like in the case of Coco/R, adding complexity and overhead due to the additional process layer. Important to also mention is that its tooling and extensibility are less modern compared to \Gls{antlr4} and the tool is heavily based on traditional compilers.

Despite these challenges, Bison is a good choice for performance-critical applications where an LR parser is preferred and cross-language execution is acceptable.

\subsection{Option - Custom Implementation}
\label{sec:parser-technology-option-custom}

A custom implementation provides full control over the lexer, parser, and subsequent processing, making it a suitable option for projects with specific requirements or performance constraints. By manually designing a lexer and parser in TypeScript, both speed and memory usage can be optimised while avoiding the overhead associated with general-purpose parser generators.

The primary advantage of a custom parser is its flexibility. Unlike for example \Gls{antlr4} or Bison, it can be precisely tailored to the needs of the project, reducing unnecessary complexity. However, this approach demands significant development effort, including manual error handling and debugging, which can be complex and time-consuming.

Additionally, developing a lexer and parser requires a deep understanding of parsing algorithms and careful handling to prevent ambiguity errors and incorrect results. In many cases, a custom implementation may ultimately be slower and less flexible than using a parser generator, as the latter benefits from years of optimisation and widespread use in compiler design, which is hard to compete with without extensive knowledge.

\subsection{Result}

Based on the analysis performed on each of the options listed in sections~\ref{sec:parser-technology-option-antlr4},~\ref{sec:parser-technology-option-coco},~\ref{sec:parser-technology-option-bison} and~\ref{sec:parser-technology-option-custom}, the following results were determined as presented in table~\ref{tab:parser-and-lexer-technology-results}.

\begin{table}[H]
	\centering
	\begin{tabular}{ |p{3.2cm}|p{2.8cm}|p{2.8cm}|p{2.8cm}|p{1.6cm}|  }
		\hline
		\multicolumn{5}{|c|}{Result values for the criteria selected in~\ref{sec:parser-and-lexer-technology-selection-criteria}} \\
		\hline
		Technology&Speed&Integration&Maintainability&Result\\
		\hline
		Antlr4&35&90&70&195\\
		Coco/R&50&40&50&140\\
		GNU Bison&50&40&40&130\\
		Custom&25&100&20&145\\
		\hline
	\end{tabular}
	\caption{Table showcasing the individual criteria and the scores each technology scored}
	\label{tab:parser-and-lexer-technology-results}
\end{table}

As presented in Table~\ref{tab:parser-and-lexer-technology-results}, Bison is the least suitable option, scoring 130 points, followed by Coco/R with 140 points. A custom implementation ranks second-best with 145 points, while \Gls{antlr4} emerges as the most suitable choice with 195 points.

Despite their performance and capabilities, both Coco/R and Bison present significant drawbacks, primarily due to their poor integration within the target environment and the additional development effort required for full utilisation. 

Furthermore, while a custom parser implementation offers advantages in flexibility and control, it would likely under-perform compared to other options and demand substantial effort to maintain and develop further.

This result supports the pre-existing decision presented in section~\ref{sec:technology-background}.

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../thesis"
%%% End: